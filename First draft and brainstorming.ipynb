{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1. What is RL? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![rl](data/environment.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Taxi as an example of an \"easy\" environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/optimum_policy.pck','rb') as f:\n",
    "    policy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "from IPython.core.display import clear_output, display, HTML\n",
    "def step_taxi(optimum_policy,n_games=10):\n",
    "    games_solved = 0\n",
    "    taxi = gym.make('Taxi-v2')\n",
    "    while games_solved<n_games:\n",
    "        obs = taxi.reset()\n",
    "        end = False\n",
    "        while not end:\n",
    "            try:#TODO: update policy for taxi new version\n",
    "                action = optimum_policy[str(obs)]\n",
    "                obs,_,end,_ = taxi.step(action)\n",
    "                clear_output(True)\n",
    "                taxi.render()\n",
    "                time.sleep(0.25)\n",
    "            except:\n",
    "                break\n",
    "        #time.sleep(0.75)\n",
    "        games_solved += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35m\u001b[42mB\u001b[0m\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n"
     ]
    }
   ],
   "source": [
    "step_taxi(policy,n_games=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## What is a policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('274', 0), ('421', 1), ('208', 0), ('478', 1), ('199', 0), ('138', 3), ('362', 1), ('422', 1), ('191', 3), ('185', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(list(policy.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visual representation of a policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Using graph theory to represent the state space of the environment, so no need to dive into markov chains theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "![graph](data/policy graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "![graph](data/policy_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2. How is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Real world examples:\n",
    "\n",
    "- [Factories](https://www.technologyreview.com/s/601045/this-factory-robot-learns-a-new-job-overnight)\n",
    "- [Trading](https://www.pit.ai/). (Not sure about this, I have no way to tell if its legit) \n",
    "- [Business and RL](https://www.marutitech.com/businesses-reinforcement-learning/)\n",
    "- [Quora post](https://www.quora.com/What-are-some-practical-applications-of-reinforcement-learning)\n",
    "- [Deepmind](https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## what it shuold accomplish in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Talk about deepmind and where it is heading.\n",
    "talk a bit about autonomous robots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- [deepmind lab](https://deepmind.com/blog/open-sourcing-deepmind-lab/): too experimental to use seriously.\n",
    "- [paper](https://arxiv.org/pdf/1612.03801.pdf) lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3. Packages for RL environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# [Openai gym](https://gym.openai.com/docs):\n",
    "- Show some environments.\n",
    "- Explain API.\n",
    "- Hackable environments for custom research.\n",
    "- Show some example of an experimental algorithm in a customized environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# [Openai Universe](https://universe.openai.com/):\n",
    "- [Github](https://github.com/openai/universe)\n",
    "- Show some environments.\n",
    "- Explain differences with gym.\n",
    "- VNC and vectorization for environment parallelization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 4. RL backend: Building agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## [Keras-rl](https://github.com/matthiasplappert/keras-rl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Keras to build the model that the agent will use: wraps Theano and TensorFlow.\n",
    "- Available models.\n",
    "- API and functionality.\n",
    "- [Example](https://github.com/matthiasplappert/keras-rl/blob/master/examples/duel_dqn_cartpole.py) of a deep RL agent with a few lines of code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## [Universe starter agent](https://github.com/openai/universe-starter-agent):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- TensorFlow as backend. \n",
    "- Allows to dive into hardcore details on how paralelization is achieved. \n",
    "- Easy to run an [A3C](https://arxiv.org/abs/1602.01783) example (very difficult to build new agents from scratch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 5. Educational resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Introduction to deep learning and self driving cars](https://www.youtube.com/watch?v=1L0TKZQcUtA&list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf)\n",
    "- [David Silver](https://www.youtube.com/watch?v=2pWv7GOvuf0&list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT)\n",
    "- [Nando de Freitas](https://www.youtube.com/user/ProfNandoDF/videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Intro (2h15min)](https://www.youtube.com/watch?v=vq2nnJ4g6N0)\n",
    "- [Big data University online course (ML0120EN)](https://bigdatauniversity.com/blog/learn-tensorflow-and-deep-learning-together/)\n",
    "- [Udacity course](https://www.udacity.com/course/deep-learning--ud730)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
